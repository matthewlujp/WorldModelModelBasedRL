{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginners\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255., x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax: [[0.06551202 0.10176755 0.10221194 0.09102646 0.20914747 0.12792437\n",
      "  0.13070227 0.02745285 0.05136614 0.09288896]\n",
      " [0.11282706 0.09303643 0.06275751 0.13158062 0.21336561 0.11631046\n",
      "  0.10072237 0.03072745 0.09185615 0.04681639]\n",
      " [0.1524573  0.1176155  0.09211686 0.09854499 0.07904945 0.13464382\n",
      "  0.09854833 0.07649301 0.0567124  0.09381834]\n",
      " [0.08792618 0.09525195 0.0839536  0.13422942 0.13698672 0.16202153\n",
      "  0.08478946 0.0313777  0.10290521 0.08055819]\n",
      " [0.10210298 0.07720765 0.07102622 0.12999284 0.15048036 0.12593955\n",
      "  0.11515926 0.03752364 0.06432055 0.12624691]]\n",
      "loss: 2.239328384399414\n"
     ]
    }
   ],
   "source": [
    "predictions = model(x_train[:5])\n",
    "softmaxes = tf.nn.softmax(predictions)\n",
    "loss = loss_fn(y_train[:5], predictions)\n",
    "\n",
    "print(\"softmax: {}\\nloss: {}\".format(softmaxes.numpy(), loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('log', 'fit', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2944 - accuracy: 0.9138 - val_loss: 0.1376 - val_accuracy: 0.9589\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1414 - accuracy: 0.9580 - val_loss: 0.1048 - val_accuracy: 0.9693\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1052 - accuracy: 0.9681 - val_loss: 0.0832 - val_accuracy: 0.9744\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0856 - accuracy: 0.9736 - val_loss: 0.0781 - val_accuracy: 0.9752\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0735 - accuracy: 0.9766 - val_loss: 0.0675 - val_accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x135aff290>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0702 - accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07015503197908401, 0.9783999919891357]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experts\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "x_train, x_test = x_train[..., tf.newaxis], x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        return x\n",
    "        \n",
    "model = NewModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_obj(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_obj(labels, predictions)\n",
    "    test_loss(loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = os.path.join(\"logs\", \"gradient_tape\", current_time, \"train\")\n",
    "test_log_dir = os.path.join(\"logs\", \"gradient_tape\", current_time, \"test\")\n",
    "\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 --- Loss: 0.001, Acc: 1.000, Test Loss: 0.114, Test Acc: 0.983\n",
      "EPOCH 2 --- Loss: 0.003, Acc: 0.999, Test Loss: 0.106, Test Acc: 0.984\n",
      "EPOCH 3 --- Loss: 0.001, Acc: 1.000, Test Loss: 0.107, Test Acc: 0.983\n",
      "EPOCH 4 --- Loss: 0.002, Acc: 0.999, Test Loss: 0.121, Test Acc: 0.982\n",
      "EPOCH 5 --- Loss: 0.002, Acc: 1.000, Test Loss: 0.109, Test Acc: 0.984\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "                \n",
    "    for images, labels in test_ds:\n",
    "        test_step(images, labels)\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "        \n",
    "        \n",
    "    print(\"EPOCH {} --- Loss: {:.3f}, Acc: {:.3f}, Test Loss: {:.3f}, Test Acc: {:.3f}\".format(\n",
    "        epoch + 1, train_loss.result(), train_accuracy.result(), test_loss.result(), test_accuracy.result(),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
